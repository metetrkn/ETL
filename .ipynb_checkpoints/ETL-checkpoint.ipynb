{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750d5281",
   "metadata": {},
   "source": [
    "# Downloading File into System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a116c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing related files\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0227a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-02 20:19:17--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2707 (2.6K) [application/zip]\n",
      "Saving to: ‘source.zip’\n",
      "\n",
      "source.zip          100%[===================>]   2.64K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-09-02 20:19:17 (1.80 GB/s) - ‘source.zip’ saved [2707/2707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# donwloading files for ETL op. from net\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62ad068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  source.zip\r\n",
      "  inflating: source3.json            \r\n",
      "  inflating: source1.csv             \r\n",
      "  inflating: source2.csv             \r\n",
      "  inflating: source3.csv             \r\n",
      "  inflating: source1.json            \r\n",
      "  inflating: source2.json            \r\n",
      "  inflating: source1.xml             \r\n",
      "  inflating: source2.xml             \r\n",
      "  inflating: source3.xml             \r\n"
     ]
    }
   ],
   "source": [
    "# source zip file downloaded, unziping it!\n",
    "!unzip source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222bf0e3",
   "metadata": {},
   "source": [
    "# Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e4fd0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv files extraction function\n",
    "def extract_csv():\n",
    "    # capturing all csv files in current dir as strings of python list\n",
    "    csv_files = glob.glob('*.csv')\n",
    "    # creating an empty data frame to concat all csv files on it\n",
    "    df_csv = pd.DataFrame()\n",
    "    # transforming each csv file and concatinating in df\n",
    "    for csv in csv_files:\n",
    "        df_temp = pd.read_csv(csv)\n",
    "        df_csv = pd.concat([df_csv, df_temp], ignore_index=True)\n",
    "    # returning df as all csv files concatinated version\n",
    "    return df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ec4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json files extraction function\n",
    "def extract_json():\n",
    "    # capturing all json files in current dir as strings of python list\n",
    "    json_files = glob.glob('*.json')\n",
    "    # creating an empty data frame to concat all csv files on it\n",
    "    df_json = pd.DataFrame()\n",
    "    # transforming each csv file and concatinating in df\n",
    "    for json in json_files:\n",
    "        df_temp = pd.read_json(json, lines=True)\n",
    "        df_json = pd.concat([df_json, df_temp], ignore_index=True)\n",
    "    # returning df as all csv files concatinated version\n",
    "    return df_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d94f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml files extraction function\n",
    "def extract_xml():\n",
    "    # capturing all xml files in current dir as strings of python list\n",
    "    xml_files = glob.glob('*.xml')\n",
    "\n",
    "    # list to store data from xml files\n",
    "    data = []\n",
    "    # capturing data from xml files\n",
    "    for file in xml_files:\n",
    "        # creating xml tree and root\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()\n",
    "        # craeating updating df_xml with captured data in xml files\n",
    "        for person in root:\n",
    "            name = person.find(\"name\").text\n",
    "            height = float(person.find(\"height\").text)\n",
    "            weight = float(person.find(\"weight\").text)\n",
    "            data.append({'name':name, 'height':height, 'weight':weight})\n",
    "    # creating data frame from data\n",
    "    return pd.DataFrame(data, columns=['name', 'height', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f0fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general extract function\n",
    "def extract_all():\n",
    "    extracted_data = pd.concat([extract_csv(), extract_json(), extract_xml()],\n",
    "                              ignore_index=True)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264a641",
   "metadata": {},
   "source": [
    "# Transformation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47746b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data_to_transform):\n",
    "    # transforming height from inches to cm\n",
    "    data_to_transform.height = round(data_to_transform.height * 2.54, 2)\n",
    "    # transforming weight from poind to kilogram\n",
    "    data_to_transform.weight = round(data_to_transform.weight * 0.45359237,2)\n",
    "    \n",
    "    return data_to_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2dd9a6",
   "metadata": {},
   "source": [
    "# Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47525d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding transformed function into external file\n",
    "def load(transformed_data):\n",
    "    where_to = './result.csv'\n",
    "    transform(transformed_data).to_csv(where_to, index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af3fbc",
   "metadata": {},
   "source": [
    "# Logging Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cab173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    # Year-Monthname-Day-Hour-Minute-Second\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' \n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    mes = timestamp + ', ' + message + '\\n'\n",
    "    with open('./logfile.txt', 'a') as f:\n",
    "        f.write(mes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ab79e",
   "metadata": {},
   "source": [
    "# Running ETL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4729c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction\n",
    "log('Etl Job Started')\n",
    "extracted_data = extract_all()\n",
    "log('Extraction phase is Done!')\n",
    "\n",
    "# transformation\n",
    "log('Transformation Job Started')\n",
    "transformed_data = transform(extracted_data)\n",
    "log('Transformation phase is Done!')\n",
    "\n",
    "# loading\n",
    "log('Loading Job Started')\n",
    "load(transformed_data)\n",
    "log('Loading phase is Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75683b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
